{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UNBA_ES_u7Ve",
        "outputId": "54dfcd0c-734d-488e-b7d2-0db84dad48c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.37.13-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.38.0,>=1.37.13 (from boto3)\n",
            "  Downloading botocore-1.37.13-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.13->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.13->boto3) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.13->boto3) (1.17.0)\n",
            "Downloading boto3-1.37.13-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.13-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.37.13 botocore-1.37.13 jmespath-1.0.1 s3transfer-0.11.4\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.44)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain_aws\n",
            "  Downloading langchain_aws-0.2.15-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: boto3>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from langchain_aws) (1.37.13)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.11/dist-packages (from langchain_aws) (0.3.44)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain_aws) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_aws) (2.10.6)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.13 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.37.0->langchain_aws) (1.37.13)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.37.0->langchain_aws) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.37.0->langchain_aws) (0.11.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (0.3.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_aws) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_aws) (2.27.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.13->boto3>=1.37.0->langchain_aws) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.13->boto3>=1.37.0->langchain_aws) (2.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.13->boto3>=1.37.0->langchain_aws) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.3.1)\n",
            "Downloading langchain_aws-0.2.15-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_aws\n",
            "Successfully installed langchain_aws-0.2.15\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3\n",
        "!pip install langchain\n",
        "!pip install langchain_aws"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running an AWS-Hosted LLM with LangChain\n",
        "\n",
        "In this demo notebook, we demonstrate how to use the boto3 Python SDK along with the abstractions available through the LangChain package to work with Amazon Bedrock Foundation Models."
      ],
      "metadata": {
        "id": "2v5m0bLLyFV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from langchain_aws import BedrockLLM\n",
        "from langchain_aws import ChatBedrock"
      ],
      "metadata": {
        "id": "0HLcJJVZvO3_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AWS_DEFAULT_REGION=\"...\"\n",
        "AWS_ACCESS_KEY_ID=\"...\"\n",
        "AWS_SECRET_ACCESS_KEY=\"...\"\n",
        "AWS_SESSION_TOKEN=\"...\""
      ],
      "metadata": {
        "id": "v0qxRMSZvae3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing available models\n",
        "\n",
        "Here we can see which foundation models Bedrock as access to.  However, remember that not all of these are active for this workshop."
      ],
      "metadata": {
        "id": "AonF5PGExHQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[models['modelId'] for models in boto3_bedrock.list_foundation_models()['modelSummaries']]"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI2Nmbd5vh9G",
        "outputId": "60ded3b7-a1cb-4298-89cc-771f1e21ba5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amazon.titan-tg1-large',\n",
              " 'amazon.titan-embed-g1-text-02',\n",
              " 'amazon.titan-text-lite-v1:0:4k',\n",
              " 'amazon.titan-text-lite-v1',\n",
              " 'amazon.titan-text-express-v1:0:8k',\n",
              " 'amazon.titan-text-express-v1',\n",
              " 'amazon.nova-pro-v1:0',\n",
              " 'amazon.nova-lite-v1:0',\n",
              " 'amazon.nova-micro-v1:0',\n",
              " 'amazon.titan-embed-text-v1:2:8k',\n",
              " 'amazon.titan-embed-text-v1',\n",
              " 'amazon.titan-embed-text-v2:0',\n",
              " 'amazon.titan-embed-image-v1:0',\n",
              " 'amazon.titan-embed-image-v1',\n",
              " 'amazon.titan-image-generator-v1:0',\n",
              " 'amazon.titan-image-generator-v1',\n",
              " 'amazon.titan-image-generator-v2:0',\n",
              " 'amazon.rerank-v1:0',\n",
              " 'stability.stable-diffusion-xl-v1:0',\n",
              " 'stability.stable-diffusion-xl-v1',\n",
              " 'stability.sd3-large-v1:0',\n",
              " 'stability.sd3-5-large-v1:0',\n",
              " 'stability.stable-image-core-v1:0',\n",
              " 'stability.stable-image-core-v1:1',\n",
              " 'stability.stable-image-ultra-v1:0',\n",
              " 'stability.stable-image-ultra-v1:1',\n",
              " 'anthropic.claude-3-5-sonnet-20241022-v2:0:18k',\n",
              " 'anthropic.claude-3-5-sonnet-20241022-v2:0:51k',\n",
              " 'anthropic.claude-3-5-sonnet-20241022-v2:0:200k',\n",
              " 'anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
              " 'anthropic.claude-3-7-sonnet-20250219-v1:0',\n",
              " 'anthropic.claude-3-5-haiku-20241022-v1:0',\n",
              " 'anthropic.claude-instant-v1:2:100k',\n",
              " 'anthropic.claude-instant-v1',\n",
              " 'anthropic.claude-v2:0:18k',\n",
              " 'anthropic.claude-v2:0:100k',\n",
              " 'anthropic.claude-v2:1:18k',\n",
              " 'anthropic.claude-v2:1:200k',\n",
              " 'anthropic.claude-v2:1',\n",
              " 'anthropic.claude-v2',\n",
              " 'anthropic.claude-3-sonnet-20240229-v1:0:28k',\n",
              " 'anthropic.claude-3-sonnet-20240229-v1:0:200k',\n",
              " 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
              " 'anthropic.claude-3-haiku-20240307-v1:0:48k',\n",
              " 'anthropic.claude-3-haiku-20240307-v1:0:200k',\n",
              " 'anthropic.claude-3-haiku-20240307-v1:0',\n",
              " 'anthropic.claude-3-opus-20240229-v1:0:12k',\n",
              " 'anthropic.claude-3-opus-20240229-v1:0:28k',\n",
              " 'anthropic.claude-3-opus-20240229-v1:0:200k',\n",
              " 'anthropic.claude-3-opus-20240229-v1:0',\n",
              " 'anthropic.claude-3-5-sonnet-20240620-v1:0:18k',\n",
              " 'anthropic.claude-3-5-sonnet-20240620-v1:0:51k',\n",
              " 'anthropic.claude-3-5-sonnet-20240620-v1:0:200k',\n",
              " 'anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
              " 'cohere.command-text-v14:7:4k',\n",
              " 'cohere.command-text-v14',\n",
              " 'cohere.command-r-v1:0',\n",
              " 'cohere.command-r-plus-v1:0',\n",
              " 'cohere.command-light-text-v14:7:4k',\n",
              " 'cohere.command-light-text-v14',\n",
              " 'cohere.embed-english-v3:0:512',\n",
              " 'cohere.embed-english-v3',\n",
              " 'cohere.embed-multilingual-v3:0:512',\n",
              " 'cohere.embed-multilingual-v3',\n",
              " 'cohere.rerank-v3-5:0',\n",
              " 'deepseek.r1-v1:0',\n",
              " 'meta.llama3-8b-instruct-v1:0',\n",
              " 'meta.llama3-70b-instruct-v1:0',\n",
              " 'meta.llama3-1-8b-instruct-v1:0:128k',\n",
              " 'meta.llama3-1-8b-instruct-v1:0',\n",
              " 'meta.llama3-1-70b-instruct-v1:0:128k',\n",
              " 'meta.llama3-1-70b-instruct-v1:0',\n",
              " 'meta.llama3-1-405b-instruct-v1:0',\n",
              " 'meta.llama3-2-11b-instruct-v1:0:128k',\n",
              " 'meta.llama3-2-11b-instruct-v1:0',\n",
              " 'meta.llama3-2-90b-instruct-v1:0:128k',\n",
              " 'meta.llama3-2-90b-instruct-v1:0',\n",
              " 'meta.llama3-2-1b-instruct-v1:0:128k',\n",
              " 'meta.llama3-2-1b-instruct-v1:0',\n",
              " 'meta.llama3-2-3b-instruct-v1:0:128k',\n",
              " 'meta.llama3-2-3b-instruct-v1:0',\n",
              " 'meta.llama3-3-70b-instruct-v1:0',\n",
              " 'mistral.mistral-7b-instruct-v0:2',\n",
              " 'mistral.mixtral-8x7b-instruct-v0:1',\n",
              " 'mistral.mistral-large-2402-v1:0',\n",
              " 'mistral.mistral-large-2407-v1:0',\n",
              " 'luma.ray-v2:0']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Bedrock runtime client\n",
        "\n",
        "In this next code block, a dedicated boto3 client for the bedrock-runtime service is created.  This client is responsible for executing runtime operations, such as invoking a model with a given prompt."
      ],
      "metadata": {
        "id": "N4rEcEt8xZGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bedrock_runtime = boto3.client(\n",
        "    'bedrock-runtime',\n",
        "    region_name=AWS_DEFAULT_REGION,\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    aws_session_token=AWS_SESSION_TOKEN\n",
        ")"
      ],
      "metadata": {
        "id": "50FnNprfvlEJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing BedrockLLM and invoking a model\n",
        "\n",
        "Here, the BedrockLLM class from the langchain_aws package is instantiated.  This class serves as a high-level wrapper to interface with AWS-hosted LLMs.\n",
        "The initialization parameters include the model ID (in this case, \"amazon.titan-tg1-large\"), region, and the necessary AWS credentials.  Once the instance is created, the invoke method is used to send a prompt (\"What is the recipe of mayonnaise?\") to the model.  This section demonstrates the fundamental workflow: setting up the model wrapper and making a basic invocation call to test the model’s response, providing a concrete example of how to interact with AWS-hosted generative AI models using LangChain.\n",
        "\n",
        "Try several different prompts here to see what different types of answers you can get!"
      ],
      "metadata": {
        "id": "BMgGTXrcyhu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = BedrockLLM(\n",
        "    model_id=\"amazon.titan-tg1-large\",\n",
        "    region_name=AWS_DEFAULT_REGION,\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    aws_session_token=AWS_SESSION_TOKEN\n",
        ")\n",
        "\n",
        "llm.invoke(input='What is the recipe of mayonnaise?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "J2fkBhf7vqa7",
        "outputId": "b7a70ec9-ade0-45f2-9d9a-bb1583426124"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. Mayonnaise is made by combining oil, egg yolk, and an acid, either lemon juice or vinegar, in a process known as emulsification. The oil and egg yolk are initially whisked together to create a thick and creamy mixture.\\n2. The acid is then gradually added to the mixture while whisking continuously. This causes the oil and egg yolk to combine and form an emulsion, which is a mixture of two liquids that do not normally mix, such as oil and water.\\n3. The mayonnaise can be customized by adding additional ingredients such as mustard, herbs, or spices. It'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing ChatBedrock\n",
        "\n",
        "BedrockLLM is designed for single-turn, prompt-based interactions where you provide the prompt (\"What is the recipe for mayonnaise?\") and the model generates an output in one go.  This is fine for simple things, but when you need to have more sophisticated interactions you want something that supports chat-like exchanges where the model can manage context over several turns of dialogue.  Additionally, not all of the available models, including more sophisticated models like Anthropic's Claude 3 Sonnet below, are supported by BedrockLLM.  Hence, we have the more sophisticated ChatBedrock, as shown below.\n",
        "\n",
        "Also note that the output of ChatBedrock contains much more information than just a text output."
      ],
      "metadata": {
        "id": "eeSlQXzQy2BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm = ChatBedrock(\n",
        "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
        "    region_name=AWS_DEFAULT_REGION,\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    aws_session_token=AWS_SESSION_TOKEN\n",
        ")\n",
        "\n",
        "chat_llm.invoke(input=\"What is the recipe of mayonnaise?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOuGMr5bvtgN",
        "outputId": "66f632a6-5340-4af1-c1e6-e9cfa7cc7fef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Here is a basic recipe for homemade mayonnaise:\\n\\nIngredients:\\n- 1 egg yolk\\n- 1 tablespoon lemon juice or white wine vinegar\\n- 1 teaspoon Dijon mustard (optional, for flavor)\\n- 1/4 teaspoon salt\\n- 3/4 cup neutral oil (like canola, vegetable or grapeseed oil)\\n\\nInstructions:\\n\\n1. In a medium bowl, whisk together the egg yolk, lemon juice/vinegar, mustard (if using), and salt.\\n\\n2. Very slowly, while whisking constantly, drizzle in a few drops of the oil until the mixture begins to thicken and emulsify.\\n\\n3. Still whisking constantly, drizzle in the remaining oil a few drops at a time until fully incorporated and the mayonnaise is thick.\\n\\n4. If it gets too thick, you can whisk in a teaspoon or two of warm water to thin it out.\\n\\n5. Taste and adjust seasoning if needed by adding more lemon juice, vinegar or salt.\\n\\nThe key is to add the oil very slowly while whisking vigorously to allow a stable emulsion to form. This basic mayo can be flavored with herbs, garlic, smoked paprika, etc. Refrigerate for up to 5 days.', additional_kwargs={'usage': {'prompt_tokens': 16, 'completion_tokens': 306, 'total_tokens': 322}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 16, 'completion_tokens': 306, 'total_tokens': 322}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-b9b14219-f33e-44b8-b6e4-b2190af12439-0', usage_metadata={'input_tokens': 16, 'output_tokens': 306, 'total_tokens': 322})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temperature\n",
        "\n",
        "Temperature is the thing that gives models creativity.  It controls the randomness of the model's responses.  Setting it to 0.0 (the minimum) typically results in a more deterministic and consistent output while setting it to 1.0 (the maximum) results in more creative responses.  Experiment with the temperature setting in the following cell to see how the output changes as a result."
      ],
      "metadata": {
        "id": "rjh18jKBz1aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm = ChatBedrock(\n",
        "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
        "    region_name=AWS_DEFAULT_REGION,\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    aws_session_token=AWS_SESSION_TOKEN,\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "chat_llm.invoke(input=\"What is the recipe of mayonnaise?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr7xxkXuvx5-",
        "outputId": "fdca4fd7-1ffa-4a02-b4ae-d1db5fb7a4ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Here is a basic recipe for homemade mayonnaise:\\n\\nIngredients:\\n- 1 egg yolk\\n- 1 tablespoon lemon juice or white wine vinegar\\n- 1/2 teaspoon Dijon mustard (optional)\\n- 1/4 teaspoon salt\\n- 3/4 cup vegetable oil or mild olive oil\\n\\nInstructions:\\n\\n1. In a medium bowl, whisk together the egg yolk, lemon juice/vinegar, mustard (if using), and salt.\\n\\n2. Very slowly, while whisking constantly, drizzle in the oil just a few drops at a time at first. This allows the mixture to emulsify properly.\\n\\n3. Once about 1/4 cup of oil has been incorporated, you can start adding the oil in a thin steady stream while whisking vigorously. \\n\\n4. Continue whisking and adding oil until all the oil is incorporated and the mayonnaise is thick.\\n\\n5. Taste and adjust seasoning if needed by adding more lemon juice, salt, etc.\\n\\n6. Transfer to an airtight container and refrigerate for up to 1 week.\\n\\nThe key is adding the oil very slowly at first to allow the emulsion to form properly. This gives mayonnaise its thick, creamy texture.', additional_kwargs={'usage': {'prompt_tokens': 16, 'completion_tokens': 294, 'total_tokens': 310}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 16, 'completion_tokens': 294, 'total_tokens': 310}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-bbf8a345-d5bf-4a0f-969f-4c57cbf6b50d-0', usage_metadata={'input_tokens': 16, 'output_tokens': 294, 'total_tokens': 310})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limiting the number of tokens returned\n",
        "\n",
        "The cost of using an LLM is dependent on how many tokens are sent back and forth with the model.  The `max_tokens` parameter can provide a limit on how many total tokens are returned.  Limiting the token count can be useful when you need to ensure that the responses remain concise or when working within strict output size constraints.  Experiment with a few different values for this to see how the output changes."
      ],
      "metadata": {
        "id": "FXm4C_hl0RVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm = ChatBedrock(\n",
        "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
        "    region_name=AWS_DEFAULT_REGION,\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    aws_session_token=AWS_SESSION_TOKEN,\n",
        "    temperature=0.0,\n",
        "    max_tokens=10\n",
        ")\n",
        "\n",
        "chat_llm.invoke(input=\"What is the recipe of mayonnaise?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQVmJgYgv6tw",
        "outputId": "d9ebffe0-5f9f-44f5-9e5e-b1cc9052721a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Here is a basic recipe for homemade may', additional_kwargs={'usage': {'prompt_tokens': 16, 'completion_tokens': 10, 'total_tokens': 26}, 'stop_reason': 'max_tokens', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 16, 'completion_tokens': 10, 'total_tokens': 26}, 'stop_reason': 'max_tokens', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-66e34ff9-fad3-4e7a-a496-21bd227ea222-0', usage_metadata={'input_tokens': 16, 'output_tokens': 10, 'total_tokens': 26})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbcxV4zIwSDx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}